# ğŸ“Š ETL Data Pipeline

Proyecto de **IngenierÃ­a de Datos** con un pipeline ETL (Extract, Transform, Load).  
Los datos se extraen de una API pÃºblica, se transforman con **pandas** y se cargan en **PostgreSQL**.

# Para ejecutar:
- crear una conexion en dbeaver (o a postgreSQL)
- seguir paso a paso el archivo "postgre_creator.sql" 

# ğŸš€ TecnologÃ­as
- Python
- pandas
- PostgreSQL
- Apache Airflow / Prefect `proximamente`
- Docker

## ğŸ“‚ Estructura
- `extract/` â†’ scripts de extracciÃ³n de datos.
- `transform/` â†’ limpieza y normalizaciÃ³n.
- `load/` â†’ carga a la base de datos.
- `dags/` â†’ futuros flujos de Airflow.

### Por quÃ© opte por esta estructura?
- Modular: cada etapa ETL es independiente â†’ fÃ¡cil mantenimiento.
- Preparada para migrar a Airflow: despuÃ©s podÃ©s convertir cada script en una tarea (PythonOperator).

## ğŸ’¡ PrÃ³ximos pasos
- Agregar orquestaciÃ³n con Airflow.
- Conectar con dashboard de visualizaciÃ³n.
