# ðŸ“Š ETL Data Pipeline

Proyecto de **IngenierÃ­a de Datos** con un pipeline ETL (Extract, Transform, Load).  
Los datos se extraen de una API pÃºblica, se transforman con **pandas** y se cargan en **PostgreSQL**.

# Para ejecutar:
- configura tu base de datos (PostgreSQL):
`CREATE DATABASE etl_db;`
`CREATE USER etl_user WITH ENCRYPTED PASSWORD 'etl_password';`
`GRANT ALL PRIVILEGES ON DATABASE etl_db TO etl_user;`

- Para ejecutar el script, usa `python scripts/etl_pipeline.py`.

# ðŸš€ TecnologÃ­as
- Python
- pandas
- PostgreSQL
- Apache Airflow / Prefect
- Docker

## ðŸ“‚ Estructura
- `extract/` â†’ scripts de extracciÃ³n de datos.
- `transform/` â†’ limpieza y normalizaciÃ³n.
- `load/` â†’ carga a la base de datos.
- `dags/` â†’ flujos de Airflow.

## ðŸ’¡ PrÃ³ximos pasos
- Agregar orquestaciÃ³n con Airflow.
- Conectar con dashboard de visualizaciÃ³n.
